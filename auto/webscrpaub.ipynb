{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# establish connection\n",
    "cnx = mysql.connector.connect(user='root', password='',\n",
    "                              host='localhost', database='users')\n",
    "\n",
    "# create cursor object\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "# execute a query\n",
    "query = \"SELECT LAST_UPDATED,NAME FROM restaurants\"\n",
    "cursor.execute(query)\n",
    "array=[]\n",
    "# iterate over results\n",
    "for result in cursor:\n",
    "    array.append(result)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "query = 'Hotels near LAU'\n",
    "num_results = 1  # number of search results to retrieve\n",
    "\n",
    "# Send a GET request to Google's search engine\n",
    "url = f'https://www.google.com/search?q={query}&num={num_results}'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Parse the HTML response using BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "\n",
    "# Locate the search results container\n",
    "search_results = soup.find_all('div', class_='g')\n",
    "\n",
    "# Extract the necessary data from each search result\n",
    "urls = []\n",
    "queries=[]\n",
    "for result in search_results:\n",
    "    # Extract the URL of the search result\n",
    "    url = result.find('a')['href']\n",
    "    # Check if the URL is a real link and add it to the list of URLs\n",
    "    if url.startswith('http'):\n",
    "        urls.append(url)\n",
    "    \n",
    "# Query each website and extract the last updated time\n",
    "for url in urls:\n",
    "    # Send a GET request to the website\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the HTML response using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'lxml')\n",
    "    \n",
    "    time_tag = soup.find('time')\n",
    "    if time_tag:\n",
    "        last_updated_time = time_tag.text\n",
    "        print(f'URL: {url}, Last Updated Time: {last_updated_time}')\n",
    "        queries.append(last_updated_time)\n",
    "    else:\n",
    "        print(f'URL: {url}, Last Updated Time not found')\n",
    "for db_result, web_result in zip(array, queries):\n",
    "    # compare the last updated time values\n",
    "    if db_result[0] != web_result:\n",
    "        # print the differences\n",
    "        print(f\"Name: {db_result[1]}, Last Updated (DB): {db_result[0]}, Last Updated (Web): {web_result}\")\n",
    "\n",
    "cursor.close()\n",
    "cnx.close()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
